# Hierarchical Music Behaviors: From Concept to Sound

> **Status**: Deep Exploration
> **Parent**: MUSICAL-BEHAVIORS.md
> **Created**: 2025-01-17

This document explores the layered behavioral approach to procedural music composition, where each layer can be developed, tested, and refined independently.

---

## The Core Insight

Music composition naturally decomposes into hierarchical layers:

```
┌─────────────────────────────────────────────────────────────────┐
│  Layer 5: PIECE                                                  │
│  "A melancholic folk ballad about loss and hope"                │
├─────────────────────────────────────────────────────────────────┤
│  Layer 4: STRUCTURE                                              │
│  Intro → Verse → Chorus → Verse → Bridge → Chorus → Outro       │
├─────────────────────────────────────────────────────────────────┤
│  Layer 3: SECTION                                                │
│  "The verse: plaintive melody over sparse accompaniment"        │
├─────────────────────────────────────────────────────────────────┤
│  Layer 2: PHRASE                                                 │
│  4-bar melodic statement with rising contour, resolving down    │
├─────────────────────────────────────────────────────────────────┤
│  Layer 1: GESTURE                                                │
│  Specific note sequences, rhythms, articulations                │
└─────────────────────────────────────────────────────────────────┘
```

Each layer is a behavior that orchestrates the layer below it. Each can be:
- Written by a human
- Generated by an LLM from natural language
- Tested in isolation
- Swapped out without affecting other layers

---

## Layer 1: Gestures (Atomic Musical Units)

Gestures are the smallest meaningful musical units - a few notes that form a recognizable pattern.

```yaml
# gestures/rising_hopeful.gesture.yaml
version: "1.0"
type: gesture
metadata:
  id: rising_hopeful_4note
  description: "Four ascending notes suggesting hope or aspiration"
  emotional_character: [hopeful, ascending, gentle]
  duration_beats: 4

parameters:
  root_pitch:
    type: midi_note
    default: 60  # Middle C
  intensity:
    type: number
    range: [0.0, 1.0]
    default: 0.6
  tempo:
    type: bpm
    default: 90

output:
  notes:
    - pitch: "${root_pitch}"
      beat: 0.0
      duration: 1.0
      velocity: "${intensity * 80}"
    - pitch: "${root_pitch + 2}"  # Major 2nd up
      beat: 1.0
      duration: 1.0
      velocity: "${intensity * 85}"
    - pitch: "${root_pitch + 4}"  # Major 3rd up
      beat: 2.0
      duration: 1.5
      velocity: "${intensity * 95}"
    - pitch: "${root_pitch + 7}"  # Perfect 5th up
      beat: 3.0
      duration: 1.0
      velocity: "${intensity * 100}"
```

```yaml
# gestures/falling_melancholic.gesture.yaml
version: "1.0"
type: gesture
metadata:
  id: falling_melancholic_3note
  description: "Descending minor figure expressing sadness"
  emotional_character: [sad, descending, resigned]
  duration_beats: 3

parameters:
  root_pitch:
    type: midi_note
    default: 67
  intensity:
    type: number
    range: [0.0, 1.0]
    default: 0.5

output:
  notes:
    - pitch: "${root_pitch}"
      beat: 0.0
      duration: 1.5
      velocity: "${intensity * 90}"
    - pitch: "${root_pitch - 2}"  # Major 2nd down
      beat: 1.5
      duration: 1.0
      velocity: "${intensity * 75}"
    - pitch: "${root_pitch - 3}"  # Minor 3rd down
      beat: 2.5
      duration: 0.5
      velocity: "${intensity * 60}"
```

**Key Point**: Gestures are pure data - they don't know about context, they just produce notes when invoked with parameters.

---

## Layer 2: Phrases (Gestural Sequences)

Phrases combine gestures into musical sentences, adding rhythm and contour logic.

```yaml
# phrases/verse_melody_a.phrase.yaml
version: "1.0"
type: phrase
metadata:
  id: verse_melody_a
  description: "Opening verse melody - question phrase that rises then falls"
  duration_bars: 4
  character: [questioning, gentle, folk]

parameters:
  key:
    type: key
    default: A_minor
  tempo:
    type: bpm
    default: 90
  expressiveness:
    type: number
    range: [0.0, 1.0]
    default: 0.6

# The phrase behavior - how gestures combine
behavior:
  # Start with a hopeful rise...
  - invoke_gesture:
      gesture: rising_hopeful_4note
      parameters:
        root_pitch: "${key.tonic}"
        intensity: "${expressiveness * 0.7}"
      at_bar: 0
      beat: 0

  # Brief pause/breath
  - rest:
      duration_beats: 0.5
      at_bar: 1
      beat: 0

  # Then fall back with melancholy
  - invoke_gesture:
      gesture: falling_melancholic_3note
      parameters:
        root_pitch: "${key.tonic + 7}"  # Start from the 5th
        intensity: "${expressiveness * 0.8}"
      at_bar: 1
      beat: 0.5

  # Resolve to tonic with gentle landing
  - invoke_gesture:
      gesture: single_note_landing
      parameters:
        pitch: "${key.tonic}"
        duration: 2.0
        intensity: "${expressiveness * 0.5}"
        articulation: gentle_release
      at_bar: 2
      beat: 2

  # Bars 3-4: breathing room with sustained harmony
  - rest:
      duration_beats: 4
      purpose: "Let the phrase breathe"
```

```yaml
# phrases/verse_melody_b.phrase.yaml
version: "1.0"
type: phrase
metadata:
  id: verse_melody_b
  description: "Answer phrase - responds to phrase A, more resolved"
  duration_bars: 4
  character: [answering, warmer, resolving]
  responds_to: verse_melody_a  # Semantic link

parameters:
  key:
    type: key
    default: A_minor
  tempo:
    type: bpm
    default: 90
  expressiveness:
    type: number
    range: [0.0, 1.0]
    default: 0.6

behavior:
  # Similar opening gesture but slightly varied
  - invoke_gesture:
      gesture: rising_hopeful_4note
      parameters:
        root_pitch: "${key.tonic}"
        intensity: "${expressiveness * 0.6}"
      at_bar: 0
      beat: 0
      # Subtle variation - compress rhythm slightly
      time_scale: 0.9

  # Instead of falling, step gently up to major 6th
  - invoke_gesture:
      gesture: stepwise_ascent
      parameters:
        root_pitch: "${key.tonic + 7}"
        target_pitch: "${key.tonic + 9}"
        intensity: "${expressiveness * 0.9}"
      at_bar: 1
      beat: 0

  # Strong resolution back to tonic
  - invoke_gesture:
      gesture: descending_resolution
      parameters:
        from_pitch: "${key.tonic + 9}"
        to_pitch: "${key.tonic}"
        intensity: "${expressiveness * 1.0}"
        articulation: satisfying_cadence
      at_bar: 2
      beat: 0

  # Hold for emotional impact
  - sustain:
      duration_bars: 1.5
```

**Key Point**: Phrases orchestrate gestures with timing and relationship logic. They know "question/answer" patterns, "call/response" structures.

---

## Layer 3: Sections (Phrase Architecture)

Sections combine phrases into larger musical structures with internal coherence.

```yaml
# sections/verse_first.section.yaml
version: "1.0"
type: section
metadata:
  id: verse_first
  description: "First verse - establishing the emotional landscape"
  duration_bars: 16
  role: exposition
  emotional_arc: [tentative, opening, questioning]

parameters:
  key:
    type: key
    default: A_minor
  tempo:
    type: bpm
    default: 90
  overall_intensity:
    type: number
    range: [0.0, 1.0]
    default: 0.5
  instrumentation:
    type: instrument_set
    default: [acoustic_guitar, voice]

layers:
  # Melody layer
  melody:
    instrument: voice
    behavior:
      # First phrase pair (bars 1-8)
      - invoke_phrase:
          phrase: verse_melody_a
          parameters:
            key: "${key}"
            tempo: "${tempo}"
            expressiveness: "${overall_intensity * 0.8}"
          at_bar: 0

      - invoke_phrase:
          phrase: verse_melody_b
          parameters:
            key: "${key}"
            tempo: "${tempo}"
            expressiveness: "${overall_intensity * 0.9}"
          at_bar: 4

      # Second phrase pair - variation (bars 9-16)
      - invoke_phrase:
          phrase: verse_melody_a
          parameters:
            key: "${key}"
            tempo: "${tempo}"
            expressiveness: "${overall_intensity * 0.9}"
          at_bar: 8
          # Apply ornamental variation
          modifiers:
            - add_grace_notes: sparse
            - vary_rhythm: subtle

      - invoke_phrase:
          phrase: verse_melody_b_extended  # Different ending
          parameters:
            key: "${key}"
            tempo: "${tempo}"
            expressiveness: "${overall_intensity * 1.0}"
          at_bar: 12

  # Accompaniment layer
  accompaniment:
    instrument: acoustic_guitar
    behavior:
      - invoke_pattern:
          pattern: fingerpick_folk_minor
          parameters:
            key: "${key}"
            tempo: "${tempo}"
            density: sparse  # First verse is sparse
          duration_bars: 16
          # Chord progression embedded in pattern
          chords:
            - bar: 0
              chord: i     # A minor
            - bar: 4
              chord: iv    # D minor
            - bar: 8
              chord: v     # E (or E minor for modal feel)
            - bar: 12
              chord: i     # Return home

  # Dynamic shaping across the section
  dynamics:
    envelope:
      - bar: 0
        level: 0.4
      - bar: 8
        level: 0.6
      - bar: 14
        level: 0.7
      - bar: 16
        level: 0.5  # Settle for transition
```

```yaml
# sections/chorus.section.yaml
version: "1.0"
type: section
metadata:
  id: chorus_main
  description: "The emotional heart - where hope and loss intertwine"
  duration_bars: 8
  role: emotional_peak
  emotional_arc: [building, release, bittersweet]

parameters:
  key:
    type: key
    default: A_minor
  tempo:
    type: bpm
    default: 90
  overall_intensity:
    type: number
    range: [0.0, 1.0]
    default: 0.8
  instrumentation:
    type: instrument_set
    default: [acoustic_guitar, voice, strings, light_percussion]

layers:
  melody:
    instrument: voice
    behavior:
      # Chorus melody is stronger, more direct
      - invoke_phrase:
          phrase: chorus_hook
          parameters:
            key: "${key}"
            expressiveness: "${overall_intensity}"
          at_bar: 0

      - invoke_phrase:
          phrase: chorus_response
          parameters:
            key: "${key}"
            expressiveness: "${overall_intensity * 0.9}"
          at_bar: 4

  harmony:
    instrument: strings
    role: emotional_support
    behavior:
      # Strings enter on chorus - big emotional lift
      - invoke_pattern:
          pattern: string_pad_swell
          parameters:
            key: "${key}"
            register: mid_high
            intensity: "${overall_intensity * 0.7}"
          at_bar: 0
          duration_bars: 8
          # Strings follow a rising arc
          dynamics:
            shape: crescendo_then_settle
            peak_bar: 6

  accompaniment:
    instrument: acoustic_guitar
    behavior:
      - invoke_pattern:
          pattern: strumming_folk_anthemic
          parameters:
            key: "${key}"
            tempo: "${tempo}"
            density: full  # Richer than verse
          duration_bars: 8
          chords:
            - bar: 0
              chord: VI    # F major - relative major for lift
            - bar: 2
              chord: III   # C major
            - bar: 4
              chord: iv    # D minor
            - bar: 6
              chord: i     # A minor - home

  rhythm:
    instrument: light_percussion
    behavior:
      - invoke_pattern:
          pattern: soft_brush_folk
          parameters:
            tempo: "${tempo}"
            intensity: 0.4
          at_bar: 0
          duration_bars: 8
```

**Key Point**: Sections manage multiple instrument layers, dynamics, and chord progressions. They're the first layer where polyphony emerges.

---

## Layer 4: Structure (Section Arrangement)

Structure defines the overall form - how sections combine into a complete piece.

```yaml
# structures/folk_ballad_aaba.structure.yaml
version: "1.0"
type: structure
metadata:
  id: folk_ballad_aaba
  description: "Classic folk ballad form with verse/chorus/bridge"
  estimated_duration: "3:30"
  form: [intro, verse, chorus, verse, chorus, bridge, chorus, outro]

parameters:
  key:
    type: key
    default: A_minor
  tempo:
    type: bpm
    default: 90
  overall_mood:
    type: enum
    values: [melancholic, hopeful, bittersweet, triumphant]
    default: bittersweet

# The structural behavior
arrangement:
  # Brief instrumental intro
  - section:
      use: intro_sparse
      parameters:
        key: "${key}"
        tempo: "${tempo}"
        intensity: 0.3
      purpose: "Set the scene, establish key and mood"

  # First verse - establishing
  - section:
      use: verse_first
      parameters:
        key: "${key}"
        tempo: "${tempo}"
        overall_intensity: 0.5
        instrumentation: [acoustic_guitar, voice]
      purpose: "Introduce the story, sparse arrangement"

  # First chorus - emotional lift
  - section:
      use: chorus_main
      parameters:
        key: "${key}"
        tempo: "${tempo}"
        overall_intensity: 0.75
        instrumentation: [acoustic_guitar, voice, strings]
      transition_in:
        type: swell
        bars: 1

  # Second verse - development
  - section:
      use: verse_second
      parameters:
        key: "${key}"
        tempo: "${tempo}"
        overall_intensity: 0.6
        instrumentation: [acoustic_guitar, voice, light_percussion]
      purpose: "Story develops, slightly fuller arrangement"

  # Second chorus - fuller
  - section:
      use: chorus_main
      parameters:
        key: "${key}"
        tempo: "${tempo}"
        overall_intensity: 0.85
        instrumentation: [acoustic_guitar, voice, strings, light_percussion]

  # Bridge - contrast and development
  - section:
      use: bridge_reflective
      parameters:
        key: "${relative_major(key)}"  # Modulate for contrast
        tempo: "${tempo * 0.95}"       # Slight slowdown
        overall_intensity: 0.6
      purpose: "Moment of reflection, different perspective"
      transition_in:
        type: ritardando
        bars: 0.5

  # Final chorus - emotional peak
  - section:
      use: chorus_main
      parameters:
        key: "${key}"
        tempo: "${tempo}"
        overall_intensity: 1.0  # Maximum
        instrumentation: [acoustic_guitar, voice, strings, light_percussion, bass]
      modifiers:
        - add_vocal_harmonies: true
        - extend_final_phrase: 2_bars
      transition_in:
        type: dramatic_pause
        duration: 0.5_beats

  # Outro - resolution
  - section:
      use: outro_gentle
      parameters:
        key: "${key}"
        tempo: "${tempo * 0.9}"
        intensity: 0.4
      purpose: "Let the emotion settle, gentle release"
      fade_out:
        start_bar: 6
        duration_bars: 4
```

**Key Point**: Structure handles pacing, emotional arc, key changes, and the overall journey. It references sections but can pass different parameters to get variations.

---

## Layer 5: Piece (The Creative Vision)

The piece layer is where natural language meets structure. This is where an LLM translates intent into the structured form.

```yaml
# pieces/loss_and_hope.piece.yaml
version: "1.0"
type: piece
metadata:
  id: loss_and_hope_ballad
  title: "What We Carry"
  description: |
    A melancholic folk ballad about grief and finding hope.
    The verses tell of loss - sparse, intimate, like remembering.
    The choruses lift toward hope - not triumphant, but gentle.
    The bridge is a moment of acceptance before returning stronger.

# Creative direction (can be LLM-generated from natural language)
creative_intent:
  emotional_journey:
    opening: "Tentative, like approaching a difficult memory"
    development: "The weight of loss, but not crushing"
    peak: "Bittersweet acceptance - loss acknowledged, hope found"
    resolution: "Peace, carrying both grief and hope forward"

  sonic_palette:
    primary: "Warm acoustic guitar, fingerpicked"
    support: "Gentle strings that swell in emotional moments"
    voice: "Intimate, slightly breathy, not operatic"
    texture: "Space and breathing room, not dense"

  references:
    style: "Nick Drake meets Iron & Wine"
    avoid: "Power ballad bombast, synthetic sounds"

# Map intent to structure
realization:
  use_structure: folk_ballad_aaba
  parameters:
    key: A_minor      # Minor for melancholy, but not dark
    tempo: 88         # Contemplative pace
    overall_mood: bittersweet

  # Override/customize specific sections based on intent
  section_notes:
    verse_first:
      character: "Sparse, intimate - just voice and guitar at first"
      extra: "Let phrases breathe, don't rush"

    chorus_main:
      character: "Lift happens through strings and fuller guitar"
      extra: "Hopeful but restrained - warmth, not triumph"

    bridge_reflective:
      character: "Step back, almost spoken quality to vocal"
      modulation: "Brief visit to relative major for light"

    chorus_final:
      character: "Fullest arrangement but still tasteful"
      extra: "Add gentle vocal harmony on hook"

  # Instrumentation assignments
  instruments:
    acoustic_guitar:
      sample_library: acoustic_fingerstyle_warm
      role: foundation
    voice:
      sample_library: intimate_vocal_male  # or female, configurable
      role: melody
    strings:
      sample_library: chamber_strings_soft
      role: emotional_support
    light_percussion:
      sample_library: brush_kit_gentle
      role: subtle_texture
```

---

## The LLM Translation Layer

Here's the magic: an LLM can translate natural language into this structured format.

### Example Prompt → Piece

**Human Input**:
> "I want a piece of music that feels like walking through an autumn forest after rain.
> Melancholic but not sad - more like beautiful nostalgia. Folk-influenced, maybe
> Celtic. Should build to a moment of clarity then settle back into contemplation.
> About 3-4 minutes."

**LLM Output** (the piece YAML):

```yaml
version: "1.0"
type: piece
metadata:
  id: autumn_forest_walk
  title: "After the Rain"
  description: |
    An atmospheric folk piece evoking an autumn forest after rainfall.
    The music moves through three phases: the mist and moisture of
    early exploration, a clearing where light breaks through, and
    a return to gentle wandering.

creative_intent:
  emotional_journey:
    opening: "Mist and mystery, damp leaves underfoot, hushed"
    development: "Colors emerge, beauty in decay, nostalgia"
    peak: "Sunlight through clouds, moment of clarity"
    resolution: "Contentment, continuing the walk, peace"

  sonic_palette:
    primary: "Celtic harp arpeggios, soft and shimmering"
    secondary: "Low whistle/tin whistle for melody, plaintive"
    atmosphere: "Subtle nature sounds - distant rain, leaves"
    support: "Drone underneath, like mist"

  references:
    style: "Clannad meets Enya, with Sigur Rós atmosphere"
    key_instruments: "Celtic harp, low whistle, subtle synth pad"
    avoid: "Drums, percussion, anything jarring"

realization:
  use_structure: atmospheric_journey
  parameters:
    key: D_dorian        # Modal for Celtic feel
    tempo: 72            # Slow, contemplative walking pace
    overall_mood: nostalgic_beauty

  structure_override:
    form: [
      {section: mist_opening, bars: 16},
      {section: forest_emergence, bars: 24},
      {section: clearing_light, bars: 16},
      {section: deeper_woods, bars: 24},
      {section: sunbreak_peak, bars: 12},
      {section: return_to_mist, bars: 20},
      {section: fade_to_silence, bars: 8}
    ]
```

The LLM doesn't generate notes - it generates *structured creative direction* that lower layers interpret.

---

## Testing Each Layer Independently

### Layer 1 Test: Gesture Rendering

```bash
# Test a single gesture in isolation
abml-music render-gesture \
  --gesture rising_hopeful_4note \
  --params '{"root_pitch": 60, "intensity": 0.7}' \
  --output test_gesture.mid

# Listen and verify it sounds like "hopeful rising"
```

### Layer 2 Test: Phrase Coherence

```bash
# Test a phrase with multiple gestures
abml-music render-phrase \
  --phrase verse_melody_a \
  --params '{"key": "A_minor", "tempo": 90}' \
  --output test_phrase.mid

# Verify: Does it form a coherent musical sentence?
# Does the question-answer structure come through?
```

### Layer 3 Test: Section Orchestration

```bash
# Test a full section with multiple layers
abml-music render-section \
  --section chorus_main \
  --params '{"key": "A_minor", "overall_intensity": 0.8}' \
  --output test_section.mid

# Verify: Do instruments blend well?
# Does the emotional arc work?
# Are dynamics shaped properly?
```

### Layer 4 Test: Structural Flow

```bash
# Test the full structure
abml-music render-structure \
  --structure folk_ballad_aaba \
  --params '{"key": "A_minor", "tempo": 90}' \
  --output test_structure.mid

# Verify: Do transitions work?
# Does the emotional journey make sense?
# Is pacing appropriate?
```

### Layer 5 Test: Intent Realization

```bash
# The full pipeline from piece definition
abml-music realize-piece \
  --piece loss_and_hope.piece.yaml \
  --output final_piece.mid

# Verify: Does it match the creative intent?
# Human judgment required at this level
```

---

## Iteration Workflow

Because each layer is independent, refinement is targeted:

```
┌─────────────────────────────────────────────────────────────────┐
│  "The rising gesture sounds too mechanical"                     │
│                                                                  │
│  Fix: Adjust gesture definition                                 │
│  - Add slight velocity variation                                │
│  - Add subtle timing humanization                               │
│  - Re-render, listen, iterate                                   │
│                                                                  │
│  No changes needed to phrases, sections, or structure           │
└─────────────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────────────┐
│  "The verse feels too long before the chorus"                   │
│                                                                  │
│  Fix: Adjust structure layer only                               │
│  - Reduce verse from 16 bars to 12                              │
│  - Or: Split into verse_short and verse_full variants           │
│                                                                  │
│  Gestures and phrases remain unchanged                          │
└─────────────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────────────┐
│  "The chorus needs more emotional lift"                         │
│                                                                  │
│  Fix: Adjust section layer                                      │
│  - Add string swell earlier                                     │
│  - Increase dynamic contrast                                    │
│  - Raise intensity parameter                                    │
│                                                                  │
│  Structure and gestures unchanged                               │
└─────────────────────────────────────────────────────────────────┘
```

---

## Building the Library Over Time

As we create music, we build a reusable library:

```
music-library/
├── gestures/
│   ├── rising/
│   │   ├── hopeful_4note.gesture.yaml
│   │   ├── triumphant_arpeggio.gesture.yaml
│   │   └── tentative_reach.gesture.yaml
│   ├── falling/
│   │   ├── melancholic_3note.gesture.yaml
│   │   ├── resigned_descent.gesture.yaml
│   │   └── peaceful_resolution.gesture.yaml
│   └── sustained/
│       ├── drone_foundation.gesture.yaml
│       └── breathe_pause.gesture.yaml
│
├── phrases/
│   ├── verse/
│   │   ├── folk_question.phrase.yaml
│   │   ├── folk_answer.phrase.yaml
│   │   └── folk_lament.phrase.yaml
│   ├── chorus/
│   │   ├── anthemic_hook.phrase.yaml
│   │   └── gentle_hook.phrase.yaml
│   └── bridge/
│       └── reflective_turn.phrase.yaml
│
├── sections/
│   ├── verse_sparse.section.yaml
│   ├── verse_full.section.yaml
│   ├── chorus_building.section.yaml
│   ├── chorus_peak.section.yaml
│   └── bridge_contrast.section.yaml
│
├── structures/
│   ├── folk_ballad_aaba.structure.yaml
│   ├── atmospheric_journey.structure.yaml
│   └── simple_verse_chorus.structure.yaml
│
├── patterns/
│   ├── accompaniment/
│   │   ├── fingerpick_folk.pattern.yaml
│   │   ├── strumming_gentle.pattern.yaml
│   │   └── arpeggio_celtic.pattern.yaml
│   └── rhythm/
│       ├── brush_soft.pattern.yaml
│       └── bodhrán_celtic.pattern.yaml
│
└── pieces/
    ├── loss_and_hope.piece.yaml
    ├── autumn_forest.piece.yaml
    └── ... (generated pieces)
```

Each piece created adds to the library. The LLM can draw on existing components or suggest new ones.

---

## Integration with Game Behaviors

The music system integrates with ABML's existing capabilities:

```yaml
# An NPC bard who performs contextually
version: "3.0"
metadata:
  id: wandering_bard
  type: character_behavior

context:
  variables:
    current_performance: null
    audience_mood: neutral
    location_type: outdoor

perceptions:
  - id: audience_gathered
    type: event
    topic: npc.audience.formed

  - id: audience_mood_shift
    type: continuous
    source: npc.nearby.aggregate_mood

flows:
  start_performance:
    trigger: audience_gathered
    actions:
      # Assess context
      - analyze:
          factors: [audience_mood, location_type, time_of_day]
          result_variable: performance_context

      # Generate appropriate music
      - llm_compose:
          prompt: |
            Create a folk song for a wandering bard performing ${location_type}.
            The audience mood is ${audience_mood}.
            It's ${time_of_day}, so the energy should be ${energy_for_time}.
            The song should be ${duration_for_context} long.
          output_format: piece_yaml
          result_variable: song_definition

      # Realize the composition
      - music.realize:
          piece: "${song_definition}"
          result_variable: realized_music

      # Perform with animation sync
      - parallel:
          - music.play:
              track: "${realized_music}"
              to: nearby_clients

          - animate:
              animation: bard_perform_lute
              duration: "${realized_music.duration}"
```

---

## The Vision Realized

This architecture achieves what you described:

1. **LLMs as creative translators** - Convert natural language to structured rules
2. **Behavioral layers** - Each independently testable and refinable
3. **Deterministic execution** - Rules produce consistent, predictable music
4. **Iterative refinement** - Fix one layer without breaking others
5. **Growing library** - Each piece adds reusable components
6. **Game integration** - Music behaviors compose with character/event behaviors

The pipeline from "I want music that feels like autumn rain" to actual MIDI output is real and achievable.

---

## Next Steps

1. **Define gesture schema** - The atomic musical unit format
2. **Build phrase engine** - How gestures combine with timing
3. **Create first library** - Initial set of Celtic/folk components
4. **LLM prompt design** - Effective prompts for piece generation
5. **Rendering pipeline** - YAML → MIDI-JSON → Audio

---

*This is not a dream for the future. This is a matter of implementation.*
